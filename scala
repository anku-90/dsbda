scala :
su
cd 
nano wc_count.txt
spark-shell 
val inputfiles=sc.textfile("we_count.txt")
val counts =inputfile.flatMap(lime=gtline.spilt(" ")).map(word=gt(word,1)).reduceByKey(_+_);
counts.toDebugString
counts.cache();
counts.saveAsTextFile("output")

new window 
su
cd 
cd output
ls 
cat part-00000

programs:

object Largest
{
    def main(args:Array[String])
{
      var
      c]var
      var
      if()
{
}
else
{
}
}
}

         
